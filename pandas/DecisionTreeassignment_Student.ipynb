{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zAtrlUJSr5j6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04aa77f8466edaa534027f2cfbcbe644",
     "grade": false,
     "grade_id": "cell-dd078e49d2501697",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# AirBnB Guest Arrival Prediction \n",
    "\n",
    "**[TOTAL POINTS: 10]**\n",
    "\n",
    "\n",
    "## Learning Objective\n",
    "\n",
    "By the end of this assignment, students should be able to\n",
    "\n",
    "- Apply necessary preprocessing steps on the data to make it suitable for training a decision tree.\n",
    "\n",
    "- Fit and fine-tune a decision tree using scikit learn.\n",
    "\n",
    "- Implement impurity metric, entropy, from scratch using python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Lh7mOlQ3r5j-",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e2f7b1517f2a584f91b2f398ed41358",
     "grade": false,
     "grade_id": "cell-9ee9e45879d0f477",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Problem Description\n",
    "\n",
    "For a tourism-based country like Nepal, hospitality is a major source of income. The given data represents booking information made by foreign customers via AirBnB for the year 2018. Your task is to use this data to predict whether the customer will cancel the booking or not.\n",
    "\n",
    "Let's begin with the imports.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hzEknJFLvu2M",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38007812af0079b8c11c95473c4893c2",
     "grade": false,
     "grade_id": "cell-fc438cbf7ce0af10",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 603,
     "status": "ok",
     "timestamp": 1649150123198,
     "user": {
      "displayName": "Bijaya Khadka",
      "userId": "02776490292025123911"
     },
     "user_tz": -345
    },
    "id": "aL_puzJhr5kB",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "099c19f80624b2322e28bb504183c27d",
     "grade": false,
     "grade_id": "cell-8d997d092e9ab212",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "RANDOM_STATE = 7\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Turn off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "i49SYChir5kR",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "415ad24cc7d619541131104c8c1a4a00",
     "grade": false,
     "grade_id": "cell-f591115869ad4717",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Loading Data  \n",
    "\n",
    "Let's load our dataset using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 1804,
     "status": "ok",
     "timestamp": 1649150124996,
     "user": {
      "displayName": "Bijaya Khadka",
      "userId": "02776490292025123911"
     },
     "user_tz": -345
    },
    "id": "8YRbuEf7r5kU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3b9a79aa38dd6625e3333b63af65bbe",
     "grade": false,
     "grade_id": "cell-9afe15ebb539d6e8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "d338207c-fb7f-4d1c-a203-7b08cb6b216c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>meal</th>\n",
       "      <th>...</th>\n",
       "      <th>booking_changes</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>total_guests</th>\n",
       "      <th>net_booking_cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>737</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BB</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>BB</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>BB</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hotel  is_canceled  lead_time  arrival_date_year arrival_date_month  \\\n",
       "0  Resort Hotel            0        342               2015               July   \n",
       "1  Resort Hotel            0        737               2015               July   \n",
       "2  Resort Hotel            0          7               2015               July   \n",
       "3  Resort Hotel            0         13               2015               July   \n",
       "4  Resort Hotel            0         14               2015               July   \n",
       "\n",
       "   arrival_date_week_number  arrival_date_day_of_month  \\\n",
       "0                        27                          1   \n",
       "1                        27                          1   \n",
       "2                        27                          1   \n",
       "3                        27                          1   \n",
       "4                        27                          1   \n",
       "\n",
       "   stays_in_weekend_nights  stays_in_week_nights meal  ... booking_changes  \\\n",
       "0                        0                     0  NaN  ...               3   \n",
       "1                        0                     0   BB  ...               4   \n",
       "2                        0                     1   BB  ...               0   \n",
       "3                        0                     1  NaN  ...               0   \n",
       "4                        0                     2   BB  ...               0   \n",
       "\n",
       "  deposit_type  agent  days_in_waiting_list customer_type   adr  \\\n",
       "0   No Deposit    NaN                     0     Transient   0.0   \n",
       "1   No Deposit    NaN                     0     Transient   0.0   \n",
       "2   No Deposit    NaN                     0     Transient  75.0   \n",
       "3   No Deposit  304.0                     0     Transient  75.0   \n",
       "4   No Deposit  240.0                     0     Transient  98.0   \n",
       "\n",
       "   required_car_parking_spaces total_of_special_requests  total_guests  \\\n",
       "0                            0                         0           2.0   \n",
       "1                            0                         0           2.0   \n",
       "2                            0                         0           1.0   \n",
       "3                            0                         0           1.0   \n",
       "4                            0                         1           2.0   \n",
       "\n",
       "   net_booking_cancelled  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = 'https://drive.google.com/uc?id=1Gqk7mPLeXlx7mo8iQZM0TpcNmnyFa-LD'\n",
    "data = pd.read_csv(data_url,index_col = 0 )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "u7Rb9Kmkr5kn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4cb445e8aa2766a79c3eb8cb4dd19904",
     "grade": false,
     "grade_id": "cell-71aec4dc99952f29",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Dataset Description \n",
    "\n",
    "The given dataset is a modification of [Hotel booking demand datasets](https://www.sciencedirect.com/science/article/pii/S2352340918315191) collected by **Nuano et al.** and is available under [Creative Commons 4.0](https://creativecommons.org/licenses/by/4.0/). The dataset has a total of 26 columns and 119390 rows. Each row of the dataset represents a booking made by the client. The description of each column of the dataset is presented below. \n",
    "\n",
    "### Columns info\n",
    "\n",
    "* **hotel** - Type of hotel resort or city.\n",
    "* **is_canceled** - The label column. This indicates whether the guests canceled their booking or they checked-in\n",
    "* **lead_time** - Number of days that elapsed between the entering date of the booking into the PMS and the arrival date.\n",
    "* **arrival_date_year** - The year of the arrival date.\n",
    "* **arrival_date_month** - Month of arrival date with 12 categories: “January” to “December” expressed in numbers. 1 indicates January, and 12 indicates December. \n",
    "* **arrival_date_week_number** - Week number of the arrival date.\n",
    "* **arrival_date_day_of_month** - Day of the month of the arrival date.\n",
    "* **stays_in_weekend_nights** - Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel.\n",
    "* **stays_in_week_nights** - Number of weeknights (Monday to Friday) the guest stayed or booked to stay at the hotel.\n",
    "* **meal** - Type of meal booked. \n",
    "* **country** - Country of origin. Categories are represented in the ISO 3155–3:2013 format.\n",
    "* **market_segment** - Market segment designation. In categories, the term \"TA\" means \"Travel Agents\" and \"TO\" means \"Tour Operators\".\n",
    "* **distribution_channel** - Booking distribution channel. The term \"TA\" means \"Travel Agents\" and \"TO\" means \"Tour Operators\".\n",
    "* **is_repeated_guest** - Value indicating if the booking name was from a repeated guest (1) or not (0).\n",
    "* **reserved_room_type** - Code of room type reserved. \n",
    "* **assigned_room_type** - Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g., overbooking) or by customer request.\n",
    "* **booking_changes** - Number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation.\n",
    "* **deposit_type** - Indication on if the customer made a deposit to guarantee the booking.\n",
    "* **agent** - ID of the travel agency that made the booking.\n",
    "* **days_in_waiting_list** - Number of days the booking was in the waiting list before it was confirmed to the customer. \n",
    "* **customer_type** - Type of booking. One of Contract, Group, Transient, and Transient-party.\n",
    "* **adr** - Average Daily Rate.\n",
    "* **required_car_parking_spaces** - Number of car parking spaces required by the customer.\n",
    "* **total_of_special_requests** - Number of special requests made by the customer (e.g. twin bed or high floor)\n",
    "* **total_guests** - Total number of guests(includes adults, children, and babies).\n",
    "* **net_booking_cancelled** - A difference between the total number of the previous booking canceled and the previous booking not canceled prior to this booking. A positive value means that most of the previous bookings were not canceled by the customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PStM9LWOr5kq",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ed1ed6d4667c050eedcd8214cf9af51",
     "grade": false,
     "grade_id": "cell-f2904a95ed5f3287",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Let us have a detailed look at each of these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "GW6uHSvqr5kr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f383d194124f20a9ef266e4a494c84fa",
     "grade": false,
     "grade_id": "cell-525b0ff81677d39b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "9ddfc8f0-260a-466e-a24d-16f309260618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 119390 entries, 0 to 119389\n",
      "Data columns (total 26 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   hotel                        119390 non-null  object \n",
      " 1   is_canceled                  119390 non-null  int64  \n",
      " 2   lead_time                    119390 non-null  int64  \n",
      " 3   arrival_date_year            119390 non-null  int64  \n",
      " 4   arrival_date_month           119390 non-null  object \n",
      " 5   arrival_date_week_number     119390 non-null  int64  \n",
      " 6   arrival_date_day_of_month    119390 non-null  int64  \n",
      " 7   stays_in_weekend_nights      119390 non-null  int64  \n",
      " 8   stays_in_week_nights         119390 non-null  int64  \n",
      " 9   meal                         107451 non-null  object \n",
      " 10  country                      118902 non-null  object \n",
      " 11  market_segment               119390 non-null  object \n",
      " 12  distribution_channel         107451 non-null  object \n",
      " 13  is_repeated_guest            119390 non-null  int64  \n",
      " 14  reserved_room_type           119390 non-null  object \n",
      " 15  assigned_room_type           107451 non-null  object \n",
      " 16  booking_changes              119390 non-null  int64  \n",
      " 17  deposit_type                 119390 non-null  object \n",
      " 18  agent                        103050 non-null  float64\n",
      " 19  days_in_waiting_list         119390 non-null  int64  \n",
      " 20  customer_type                119390 non-null  object \n",
      " 21  adr                          119390 non-null  float64\n",
      " 22  required_car_parking_spaces  119390 non-null  int64  \n",
      " 23  total_of_special_requests    119390 non-null  int64  \n",
      " 24  total_guests                 119386 non-null  float64\n",
      " 25  net_booking_cancelled        119390 non-null  int64  \n",
      "dtypes: float64(3), int64(13), object(10)\n",
      "memory usage: 24.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qx-NRw5tr5kz",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25f6191e72e3334dc4d0a1b69dd66520",
     "grade": false,
     "grade_id": "cell-5618bb6a0fa8d835",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Identification of features with missing values\n",
    "\n",
    "We can see that the dataset contains both categorical and numerical features. Also, some features have missing values. Before training a decision tree, it is very important to either fill these missing values or remove rows having missing values. Let us find out the percentage of missing values(if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "27XSyz0yr5k1",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5086af1d43de50b5ea3b567d3fa6121",
     "grade": false,
     "grade_id": "cell-8c6a324c0af9a91a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "1e42f73f-787c-45ba-c2e9-bab755c2be55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent                   13.686238\n",
      "meal                    10.000000\n",
      "assigned_room_type      10.000000\n",
      "distribution_channel    10.000000\n",
      "country                  0.408744\n",
      "total_guests             0.003350\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dataset_null=(data.isna().sum()/len(data))*100.0\n",
    "dataset_null_ratio=dataset_null.drop(dataset_null[dataset_null==0].index).sort_values(ascending=False)\n",
    "print(dataset_null_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QbsL-FDsr5k9",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec7337bb1dbec013a03376b603a239d8",
     "grade": false,
     "grade_id": "cell-3c1219c961c3a78a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We can see that columns `agent`, `assigned_room_type`, `distribution_channel`, `meal`, `country`, and `total_guests` have missing values.\n",
    "\n",
    "### total_guests\n",
    "\n",
    "### Exercise 1: Drop rows with missing values in `total_guests` column\n",
    "**[POINTS: 1]** \n",
    "\n",
    "---\n",
    "**Task:** \n",
    "A negligible fraction of the data is missing for `total_guest`. Let's drop all the rows that have missing values in `total_guests`.\n",
    "\n",
    "* Use [`dropna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) method provided by pandas to drop rows with missing values in `total_guests` column.\n",
    " * Set parameters `how` and `inplace` to appropriate values.\n",
    " * Use `subset = [total_guests]` to drop only those rows having missing values in `total_guests` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "kUQbyfrnr5k-",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8855e2ec9a16c41976959926eb1694e5",
     "grade": false,
     "grade_id": "cell-e356eabd056b454c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-1-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-1-Task-1\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kQgKwsKRr5lE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d112b6a3f5a53136a8550f10767abe91",
     "grade": true,
     "grade_id": "cell-e26b39c662bc1bd9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-1-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "# INTENTIONALLY LEFT BLANK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "HaKB-CAtr5lK",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e1f7275415b5c9eb25250605416cb1d",
     "grade": false,
     "grade_id": "cell-9787ec5daabec7bd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "deletable": false,
    "editable": false,
    "id": "VMdvzSqIr5lL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fd5a288daa30a896f6758bf16a7cf44",
     "grade": false,
     "grade_id": "cell-4905c2ee2da71440",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "565031b2-33a8-4f4d-86d2-50c3587dbbd4"
   },
   "outputs": [],
   "source": [
    "data['country'].value_counts().plot(kind='bar', figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "uQfTCZujr5lS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "968d98d858a1f4cef830d80912465609",
     "grade": false,
     "grade_id": "cell-34b3f9e56a7e5e14",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We can see that most of the rows in the `country` column have the value `PRT`. We can use `PRT` to fill in the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8omagtQar5lU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff06c38275efbff05e689b193cc7cb07",
     "grade": false,
     "grade_id": "cell-8221f8af495b743b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data['country'].fillna('PRT', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0SmPQPeur5lf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c9eae0b7970325981d0db35f3d06dcd",
     "grade": false,
     "grade_id": "cell-1e18149d75a7638b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### meal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "deletable": false,
    "editable": false,
    "id": "B0tBNBpvr5lh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b27783f5388606649ee5968083cbe0c",
     "grade": false,
     "grade_id": "cell-8acbddcc6210c666",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "116577a6-c609-446d-c241-44618efbd2d9"
   },
   "outputs": [],
   "source": [
    "data['meal'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Y96FjwqYr5lq",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75993a13ae629ff36cf0b61dfe1e1979",
     "grade": false,
     "grade_id": "cell-31c7803c5a6a60de",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Filling with mode, i.e., `BB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8hkPExgRr5lr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5990956f7948549b0eca4be5692852c6",
     "grade": false,
     "grade_id": "cell-af21497aa52bcf88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data['meal'].fillna('BB', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3HbfNKIgr5l4",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "299a73923b387535189fa43917e58b26",
     "grade": false,
     "grade_id": "cell-53e781f40857daa8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Filling remaining values\n",
    "We will continue filling the remaining missing values with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aTT66WPpr5l5",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36b4e99acaac02db392a941b21bce095",
     "grade": false,
     "grade_id": "cell-cf7a0690cd42608b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data['distribution_channel'].fillna(data['distribution_channel'].mode()[0], inplace=True)\n",
    "data['agent'].fillna(data['agent'].mode()[0], inplace=True)\n",
    "data['assigned_room_type'].fillna(data['assigned_room_type'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bc37_37lr5mC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8bc320bde90f8d853cb917972d183496",
     "grade": false,
     "grade_id": "cell-42acdfa7a884464c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Previously we saw that the columns have mixed type: `int64`, `float64`, and `object`. Tree-based algorithms in [`scikit-learn`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) require all values to be numeric. We will need to convert `object` data type to numeric. There are two potential solutions to this. We can use: \n",
    "* label encoding, or\n",
    "* one-hot encoding \n",
    "Since tree-based algorithms work well with label encoding, let's use it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7vLeuEqnr5mE",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1ab5c9324ac633d54bbe75b9104ef2a",
     "grade": false,
     "grade_id": "cell-2818ba72b9183229",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Label Encoding\n",
    "\n",
    "\n",
    "### Exercise 2: Use LabelEncoder to assign a numeric value to categorical features.\n",
    "**[POINTS: 1]** \n",
    "\n",
    "---\n",
    "**Task:** \n",
    "* `cat_vars` contains a list of all object type columns in our dataset.\n",
    " * Use [`LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) to assign a numeric value to each of the categorical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "lTP1LZD1r5mE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e98361cbc18c0a80158336ab40675f31",
     "grade": false,
     "grade_id": "cell-c779ddfb4232a5f5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-2-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-2-Task-1\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cat_vars = [var for var in data.columns if data[var].dtypes=='O']\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "B7WJ6HiBr5mK",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6605faf229eb4ed75eebabd4fe49b54",
     "grade": true,
     "grade_id": "cell-1abd8f9a5fadc7d7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-2-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "assert data[cat_vars] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "deletable": false,
    "editable": false,
    "id": "kBs5oCIer5mO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "911f210643851592ea554d8485269eee",
     "grade": false,
     "grade_id": "cell-5e3852c03f593b6d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "e150ce8a-18a6-4725-eb9a-8a3191786a5f"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yerPAAOSr5mV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "296dcac397775cae883ed0dd86a92607",
     "grade": false,
     "grade_id": "cell-2107fdfcd8adfa51",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We can see that all columns now contain numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "L0-6rjLlr5mV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd8cdf34681794af75bfd5ad941dbd32",
     "grade": false,
     "grade_id": "cell-1ebe1852a5a2ff1a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Splitting the dataset\n",
    "\n",
    "Before splitting the dataset, let us check the distribution of the values in the label column, i.e., `in_canceled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "deletable": false,
    "editable": false,
    "id": "V83KHB0Jr5mW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ee3be9b7994421df1dad465b97a91fd",
     "grade": false,
     "grade_id": "cell-b150afec5fb04f93",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "d73d678e-711a-4b0d-fede-f930c06b63fb"
   },
   "outputs": [],
   "source": [
    "data['is_canceled'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "id42_LqBr5mb",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28252e8da7ce9e430dc43f36a6bd924d",
     "grade": false,
     "grade_id": "cell-c27bd40e3eb7c63e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We see that the dataset is imbalanced. This forces us to:\n",
    "* Set `stratify` to `y` while splitting the dataset so that the proportion of `is_canceled = 0`, and `is_canceled = 1` remains the same in both the train and test set. \n",
    "* Divide the data into train and test so that the test set holds `20%` of the data, i.e., set `test_size` to 0.2.  \n",
    "* Since the data is imbalanced, we could use metrics like precision, recall, or f1 score. Precision quantifies how good the model is at minimizing false positives, and recall quantifies how good the model is at minimizing false negatives. But, the f1 score takes both false positives and false negatives into account. So, we will be using the f1 score to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "FYxCO-CIr5mc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab5b3b92cabf6fd5cac1351e2e4d4cc6",
     "grade": false,
     "grade_id": "cell-be1279866aecbf61",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "3fc8b7fd-b921-4279-fcdb-2440b66a9932"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop(columns=['is_canceled'])\n",
    "y = data['is_canceled']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, stratify=y, random_state = RANDOM_STATE)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "j89L-eAGr5mq",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3a3a68d4d038329db3ebfe946861d86",
     "grade": false,
     "grade_id": "cell-b0754ffee928ef33",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Training and Evaluating a Decision Tree \n",
    "\n",
    "After preparing the data and separating it into the train and test set, it is your time to train and evaluate the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YJSm3kRzr5mq",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32522b8689f3a639103aad2869140800",
     "grade": false,
     "grade_id": "cell-287bcc841e1dae90",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "\n",
    "\n",
    "### Exercise 3: Training a Decision Tree Classifier\n",
    "\n",
    "\n",
    "**[POINTS: 1]** \n",
    "\n",
    "---\n",
    "**Task:** \n",
    "\n",
    "* Use the [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) from `scikit-learn` to train a decision tree. While creating the classifier, please make sure that: \n",
    " * You have set the variable `random_state` to `RANDOM_STATE` defined at the beginning of the assignment. \n",
    " * You are using `X_train` and `y_train` to fit the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "LUwsPoilr5mr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3d098f81df4404521da8cec51108315",
     "grade": false,
     "grade_id": "cell-a24ff1ca3ed1022f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-3-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-3-Task-1\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = None\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Td3WjHcpr5mx",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5d44810f05e6dd89f5fec77c3a9f453",
     "grade": true,
     "grade_id": "cell-b1079e4ba80dd5d4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-3-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "assert tree_clf is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "jc0qtqT5r5m1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21a9ff4d92c3f03673b6079694969758",
     "grade": false,
     "grade_id": "cell-1a9f8316e664d58a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 4: Evaluating the Decision Tree \n",
    "\n",
    "\n",
    "**[POINTS: 1]** \n",
    "\n",
    "---\n",
    "**Task:** \n",
    "\n",
    "After training our classifier, it is time to assess its performance on the train and test set. To assess its performance, you will need to: \n",
    "* Make predictions on the train and test set using [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict) method provided by `DecisionTreeClassifier` \n",
    "* Use [`f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) method to compute respective f1 score. \n",
    "\n",
    "**Note: While computing `f1_score`, please set the parameter `average` to `'weighted'` so that it computes the weighted average of the f1-score of both the classes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error around this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "OTW8ChJOr5m_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad1fd4fd6e13a7c9ae8c19060c01acaf",
     "grade": false,
     "grade_id": "cell-678388561ac2f272",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-4-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-4-Task-1\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred_train = None # Stores the prediction made by our classifier on train set\n",
    "train_f1_score = None # Stores f1-score of our classifier on train set \n",
    "y_pred = None # Stores the prediction made by our classifier on test set\n",
    "test_f1_score = None # Stores f1-score of our classifier on test set \n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xSJPYZMmr5nG",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "994ddaa9f8ac40a3af863e74db6ea328",
     "grade": true,
     "grade_id": "cell-5c7a2d027ea34b1b",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "Ex-4-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "assert y_pred_train is not None, \"Please compute prediction on test set and assign to y_pred_train\"\n",
    "assert train_f1_score is not None, \"Please compute f1 score on train set and assign to train_f1_score\"\n",
    "assert y_pred is not None, \"Please compute prediction on test set and assign to y_pred\"\n",
    "assert test_f1_score is not None, \"Please compute f1 score on test set and assign to test_f1_score\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "h_Tf3sKfr5nK",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a685544ee065d7263b92be87c9550dce",
     "grade": false,
     "grade_id": "cell-25e5a8ca33aa96d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "678283f2-9b17-4826-ab56-b3f89d141f1a"
   },
   "outputs": [],
   "source": [
    "print(\"Train f1-score = {} and Test f1-score = {}\".format(round(train_f1_score, 2), round(test_f1_score, 2)))\n",
    "print(\"The depth of our tree is {}\".format(tree_clf.get_depth()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wTfOTRLcr5nP",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59426be846dda8912bb22cc4f3128512",
     "grade": false,
     "grade_id": "cell-e17c87768935d88f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Oops! The decision tree we trained is very deep. Let us use our early stopping and pruning techniques to improve the performance of this tree. Let us start with early stopping. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_pHd-WLXr5nP",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "982e07a111249b2c845f806d74037ec2",
     "grade": false,
     "grade_id": "cell-f81adbede19e4d5b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### F1 score of the decision tree at different depth\n",
    "\n",
    "The code below trains multiple trees having different depths. The depth ranges from 1 to the depth of our tree trained earlier, i.e., 46. It also creates a plot showing the performance of these different trees on the train and test set. Your task is to look at the graph and find the least value for depth that yields the maximum f1 score on the test set. Then create a new decision tree with depth set to this optimal depth and evaluate its performance on the test set. \n",
    "\n",
    "**Note**: In real life, we evaluate the performance of the tree on a separate validation set and then find the best parameters(like depth). However, for the demonstration, we will use the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "deletable": false,
    "editable": false,
    "id": "akGkatBor5nQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b43d8ee1b0779299eaefd1ce5c6c6bd",
     "grade": false,
     "grade_id": "cell-b20f2a708e989636",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "a826a173-a8c3-4fd2-a75c-17c77343c662"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "train_scores = []\n",
    "test_socres = []\n",
    "for i in range(1, tree_clf.get_depth()+1):\n",
    "    model = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=i).fit(X_train, y_train)\n",
    "    \n",
    "    # Computing f1_score in train set\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_scores.append(f1_score(y_pred_train, y_train, average='weighted'))# f1_score on train set\n",
    "  \n",
    "    # Computing f1_score on test set\n",
    "    y_pred = model.predict(X_test) # Making Predictions\n",
    "    test_socres.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "max_test_score = np.argmax(test_socres) + 1\n",
    "# Plot of depth vs accuracy\n",
    "depth = tree_clf.get_depth()\n",
    "plt.figure(figsize = (10,5))    \n",
    "plt.plot(np.arange(1, depth+1, 1), train_scores, marker = 'o', label = 'Training')\n",
    "plt.plot(np.arange(1, depth+1, 1), test_socres, marker = 'o', label = \"Testing\")\n",
    "plt.plot([max_test_score,max_test_score], [0.7, 1.0], '--', color = 'black', alpha = 0.5)\n",
    "plt.xlabel(\"Depth/complexity\", fontsize = 17)\n",
    "plt.ylabel(\"F1 Score\", fontsize = 17)\n",
    "plt.title(\"F1 Score for different depth of decision tree\", fontsize = 17)\n",
    "plt.xticks(np.arange(1, depth+1, 1)) \n",
    "plt.yticks(np.arange(0.7, 1.05, 0.05))\n",
    "plt.legend(fontsize = 17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9xy5TN7Kr5nV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3488cfda9cb57581f80671e8f4cecfcd",
     "grade": false,
     "grade_id": "cell-3eb62d3c4174a330",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Task:** \n",
    "\n",
    "\n",
    "Use the graph above to find out the least value for depth that yields the maximum f1-score on the test set and use it to set the `optimal_depth` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "3VgCJHTQr5nV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d4e7e1aa688205371294143c1040aea",
     "grade": false,
     "grade_id": "cell-325fef7c533ad1be",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-4-Task-2"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-4-Task-2\n",
    "optimal_depth = None\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QxKoOiyGr5nZ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91f1404dc98097936123f475c51cbe55",
     "grade": true,
     "grade_id": "cell-52405b24025b1546",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-4-Task-2"
    ]
   },
   "outputs": [],
   "source": [
    "assert optimal_depth is not None, \"Please set optimal_depth to the least depth that yields maximum f1-score on test set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "HbMr4Zp4r5nc",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a8ab7d906fd8eb835c5dd77d625b8a2",
     "grade": false,
     "grade_id": "cell-742a84ace60feab9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 5: Depth Pruning/Early Stopping\n",
    "\n",
    "\n",
    "**[POINTS: 1]** \n",
    "\n",
    "---\n",
    "**Task:** \n",
    "\n",
    "Create a new decision tree with: \n",
    "* `max_depth` set to `optimal_depth` \n",
    "* `random_state` set to RANDOM_STATE\n",
    "* Use [`f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) method to compute respective f1 score on test set. Store the f1 score in the variable `test`.\n",
    "\n",
    "**Note: While using `f1_score`, please set the parameter `average` to `'weighted'` so that it computes the weighted average of the f1-score of both the classes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "IFiMXbUKr5nc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fa8ba6bbccf14dc04b065dea325b477",
     "grade": false,
     "grade_id": "cell-1f9019e6fb39bb9c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-5-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-5-Task-1\n",
    "model = None\n",
    "\n",
    "y_pred = None # Array to store predictions\n",
    "test = None # variable to hold f1-score of model on test set\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cUPPDL1or5nj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26def3b7df6ba79cadf0e02428622789",
     "grade": true,
     "grade_id": "cell-0bc669d17f82d46d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-5-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "assert model is not None, \"Please follow instructions and create a model with specified parameters\"\n",
    "assert test is not None, \"Please use variable test to store f1-score of the model on test set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "GnhBl8Esr5no",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2423c59522aa90546e77285814a656f8",
     "grade": false,
     "grade_id": "cell-ff4acc0c1117ce4a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Cost Complexity Pruning\n",
    "\n",
    "In the previous section, you used early stopping to improve the performance of the decision tree. In this section, you will use cost complexity pruning to find out the best value of alpha or `ccp_alpha`. You will then use this alpha to train a new decision tree and evaluate its performance. \n",
    "\n",
    "The code below generates two arrays: \n",
    "* **`candidate_alphas`** - an array of values of `ccp_alpha` \n",
    "* **`test_scores`** - an array to hold f1 scores computed on test set for corresponding value of `ccp_alpha` in `candidate_alphas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "deletable": false,
    "editable": false,
    "id": "3gG5FAgcr5no",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cbe78d4aa805780f66a4f29d8800d95",
     "grade": false,
     "grade_id": "cell-9b4243adaa42e39a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "05f72ae6-1ce2-4dd5-d1a2-4cbd67580e16"
   },
   "outputs": [],
   "source": [
    "path = tree_clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "ccp_alphas = sorted(ccp_alphas)\n",
    "candidate_alphas = [ccp_alphas[i] for i in range(0, 2416, 100)]\n",
    "candidate_alphas = candidate_alphas[:-2]\n",
    "\n",
    "clfs = []\n",
    "for ccp_alpha in candidate_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=RANDOM_STATE, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "    \n",
    "    \n",
    "train_scores = [f1_score(clf.predict(X_train), y_train, average='weighted') for clf in clfs]\n",
    "test_scores = [f1_score(clf.predict(X_test), y_test, average='weighted') for clf in clfs]\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.title(\"F1 Score vs alpha for training and testing sets\")\n",
    "plt.plot(candidate_alphas, train_scores, marker='o', label=\"train\",\n",
    "        drawstyle=\"steps-post\")\n",
    "plt.plot(candidate_alphas, test_scores, marker='o', label=\"test\",\n",
    "        drawstyle=\"steps-post\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "GgXqHkAbr5ns",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be1d3f4c85c58ade96b23bc0ab753090",
     "grade": false,
     "grade_id": "cell-e0d5145b21979337",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 6: Implementing cost complexity pruning\n",
    "\n",
    "\n",
    "**[POINTS: 1]** \n",
    "\n",
    "---\n",
    "\n",
    "**Task**\n",
    "\n",
    "* Find alpha in `candidate_alphas` corresponding to the maximum value in `test_scores`(created above). \n",
    "* Create a new decision tree classifier, `clf`, with `random_state` set to `RANDOM_STATE` and `ccp_alpha` set to `best_alpha`.\n",
    "\n",
    "Hint: Use `np.argmax(your_array_here)` to find out the index corresponding to maximum value of `test_scores` and then use this index to extract corresponding value of alpha from `candidate_alphas` and store it in `best_alpha`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "cwk50Rlqr5nu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bc57eaa1734915f2900cda9e77ef689",
     "grade": false,
     "grade_id": "cell-874d5e5dfa7c52e2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "dbca8865-8b9b-4a0d-8f23-df7afa8417a0",
    "tags": [
     "Ex-6-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-6-Task-1\n",
    "\n",
    "index = None\n",
    "best_alpha = None\n",
    "clf = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "### END SOLUTION\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "test_result = f1_score(clf.predict(X_test), y_test, average='weighted')\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0ykIvid7r5nw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb4751c0e94e951e53b1b102d3eef54f",
     "grade": true,
     "grade_id": "cell-05a59c9b03b13188",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-6-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "assert index is not None\n",
    "assert best_alpha is not None\n",
    "assert clf is not None, \"Please follow instructions and create a model with specified parameters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eCSZHKo2r5nz",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a8ec7705c939a252e273c8c26f06f666",
     "grade": false,
     "grade_id": "cell-854e8139c17cc21a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**We see that cost complexity pruning is better than early stopping in increasing the performance of our tree.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "SBBkwfmUr5n0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26093aaf0a5076370a0283ed6ade29f3",
     "grade": false,
     "grade_id": "cell-c2e3d3c464b915ee",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Computing Entropy\n",
    "\n",
    "Earlier, you used `scikit-learn` to train and fine-tune a decision tree. In the following tasks, you will write a function to compute impurity, i.e., entropy using python, and use it to find the feature that yields the best split in the child nodes. For this task, we will create a new dataset using a subset of columns from the previous dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "deletable": false,
    "editable": false,
    "id": "EGoIuLzlr5n0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09e173ddd0603c68626855050385e107",
     "grade": false,
     "grade_id": "cell-39415623df4e2276",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "5e2858f9-4d74-4577-c278-61d2be4c4dbb"
   },
   "outputs": [],
   "source": [
    "columns = ['hotel', 'arrival_date_year', 'distribution_channel',\n",
    "           'arrival_date_month', 'assigned_room_type', 'is_canceled']\n",
    "\n",
    "new_data = data[columns]\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KgGiVHaHr5n4",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fe37f4d26932058475868de4cb7d8e4",
     "grade": false,
     "grade_id": "cell-09595c49240b18b1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Entropy \n",
    "\n",
    "Entropy is a metric to measure the impurity in our dataset. Entropy can be computed using the following formula \n",
    "$\\text{Entropy} = - \\sum_{i=1}^{c}P_i\\log{P_i}$ \n",
    "Here, \n",
    "$c = $ Total number of labels/classes. \n",
    "$p_i = $ Probability of an item belonging to class $i$. \n",
    "\n",
    "### Exercise 7: Compute Entropy\n",
    "\n",
    "\n",
    "**[POINTS: 1]** \n",
    "\n",
    "---\n",
    "\n",
    "**Task**\n",
    "\n",
    "* Use the formula presented above as a reference and complete the function below to compute entropy. \n",
    " * `zeros_and_ones` is an array that stores the frequency of zeros and ones in `label_column` respectively.\n",
    " * `probabilities` is an array that stores the probability of zeros and ones. Use array `zeros_and_ones` to compute `probabilities`\n",
    " * `log_probabilities` is an array that stores the log(base 2) of each element of the `probabilities` array.\n",
    " * `entropy` uses `log_probabilities` to compute entropy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "yBrJTx9jr5n4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa4fc99d18ec1b53de4b697b57731ee5",
     "grade": false,
     "grade_id": "cell-8b87d8a628ba4ee6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-7-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-7-Task-1\n",
    "\n",
    "def entropy(label_column):\n",
    "    '''\n",
    "    Computes entropy in the data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    label_column : pandas.Series\n",
    "                  Column containing the labels of the dataframe.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    entropy : float\n",
    "              Entropy of the input series.\n",
    "    '''\n",
    "    \n",
    "    zeros_and_ones = np.array([len(label_column) - np.sum(label_column), np.sum(label_column)])\n",
    "    \n",
    "    \n",
    "    probabilities = None\n",
    "    log_probabilities = None\n",
    "    \n",
    "    \n",
    "    probabilities = zeros_and_ones / np.sum(zeros_and_ones)\n",
    "    log_probabilities = np.log2(probabilities)\n",
    "    \n",
    "    \n",
    "    # replace np.inf or -np.inf  with 0\n",
    "    log_probabilities[log_probabilities == -np.inf] = 0\n",
    "    log_probabilities[log_probabilities == np.inf] = 0\n",
    "    # replace np.nan with 0\n",
    "    log_probabilities = np.where(np.isnan(log_probabilities), 0, log_probabilities)\n",
    "    \n",
    "    entropy = None\n",
    "    ### BEGIN SOLUTION\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    ### END SOLUTION\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MhNVqgDsr5n7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f00fba31b0ac7cd1ed986ff8d92f6c4",
     "grade": true,
     "grade_id": "cell-3686b29d225b7e47",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-7-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### INTENTIONALLY LEFT BLANK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "p7exb70Jr5n_",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d8812c9bc86b6eb28fc5cd2dc56ddca",
     "grade": false,
     "grade_id": "cell-fa3cbee443243bff",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "An attribute may have multiple values. Each of these values creates a child node(multiway split). While computing entropy, we compute the weighted average of the entropy of each of these nodes. We divide the dataset into different splits depending upon the value of the attribute, compute entropy for each split, and finally combine the result using a weighted average. The function below that computes weighted entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_I0RgLNUr5n_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2feb372cbc7deade3d22587f5ff3d4a0",
     "grade": false,
     "grade_id": "cell-d9c796539331920b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def weighted_entropy(dataframe, column_name, label_column):\n",
    "    '''\n",
    "    Computes weighted entropy of the child nodes.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataframe : pandas.DataFrame\n",
    "                The dataframe representing the dataset.\n",
    "\n",
    "    column_name : String\n",
    "                  Name of the column/attribute used for splitting.\n",
    "    \n",
    "    label_column : String\n",
    "                   Name of the column that represents the output label.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    weighted_entropy : float\n",
    "                       Weighted entropy of the child nodes.\n",
    "    '''\n",
    "\n",
    "    grouped_df = dataframe.groupby(column_name)\n",
    "    values = dataframe[column_name].unique()\n",
    "    weighted_entropy = 0\n",
    "    total_length_of_dataframe = len(dataframe)\n",
    "    for value in values:\n",
    "        group = grouped_df.get_group(value)\n",
    "        group_entropy = entropy(group[label_column])\n",
    "        weighted_entropy += (float(len(group))/total_length_of_dataframe) * group_entropy\n",
    "    return weighted_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "ob_kVgMOr5oC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ff23db26115402c3d428842e5a33f6e",
     "grade": false,
     "grade_id": "cell-6cb200ec57992864",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "e335ef44-555c-4bad-91b7-b4e1d7884c27"
   },
   "outputs": [],
   "source": [
    "entropy(new_data['is_canceled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "aAB_MZ0ar5oF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70cc610939d80ebb078a1c55f0e1c97b",
     "grade": false,
     "grade_id": "cell-3f9da62ee25f29db",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "d96617c5-f60c-48f4-bb3d-a1b2c9cd3a75"
   },
   "outputs": [],
   "source": [
    "for column in columns[:-1]:\n",
    "    print(\"Splitting column {} yields an entropy {} in child nodes\".format(column, weighted_entropy(new_data, column, 'is_canceled')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lCyW5NzLF1F6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90050373fea532f1999bd8909099a327",
     "grade": false,
     "grade_id": "cell-011d6d50b8cb3930",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Regression Tree using Scikit-learn\n",
    "In this section, we will sligthly modify the data and formulate a regression problem for you. We will add **stays_in_weekend_nights** and **stays_in_week_nights** to from a new column **stays_in_number_of_nights**.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "deletable": false,
    "editable": false,
    "id": "-aEZIPdJF1F7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1900c61c3549358a716d4bfe242ae5f",
     "grade": false,
     "grade_id": "cell-bb9adc867def9f0c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "39299e2b-6739-4147-d1dd-436a89ccb059"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vXK6KNOiF1GC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c71473a40ca8e22f8098d8c6424d76c5",
     "grade": false,
     "grade_id": "cell-6ae7855d6050df4a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data['stays_in_number_of_nights'] = data['stays_in_weekend_nights'] + data['stays_in_week_nights']\n",
    "# Drop columns stays_in_weekend_nights and stays_in_week_nights\n",
    "data_regression = data.drop(columns=['stays_in_weekend_nights', 'stays_in_week_nights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "deletable": false,
    "editable": false,
    "id": "a35z6TbJF1GG",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "842c2c7cfcdda4bcea8a1acff6072747",
     "grade": false,
     "grade_id": "cell-e416ccd66686724b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "fb471d6c-d897-4c07-bc07-2ce46d571103"
   },
   "outputs": [],
   "source": [
    "data_regression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "BsT25NgTF1GL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbcc888bc9829df4e1f4f146ca5a780c",
     "grade": false,
     "grade_id": "cell-5ccdadfcf04a8784",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X = data_regression.drop(columns=['stays_in_number_of_nights'])\n",
    "y = data_regression['stays_in_number_of_nights']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hieD8N_qF1GN",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9db4c914029a3ed00a072be17fbb5129",
     "grade": false,
     "grade_id": "cell-fc5b9c46296641a4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Let's divide the dataset into train and test set. We will keep 20% of the data in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CnHlU3nUF1GN",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "522f3c2d68e6fe041650677e6422770f",
     "grade": false,
     "grade_id": "cell-55bce9bc4e26deea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WlnzrEwAF1GP",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b1b10eca2520b1b14600f276522fa0b",
     "grade": false,
     "grade_id": "cell-7502bb0a1601d6f5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 8: Create a Regression Tree\n",
    "\n",
    "\n",
    "**[POINTS: 1]** \n",
    "\n",
    "---\n",
    "\n",
    "**Task**\n",
    "\n",
    "* Using [`DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) model provided by `scikit-learn` create a regression tree and store it in the variable `tree_reg`. \n",
    "* Train the regressor using the `fit` method and data `X_train`, `y_train`.   \n",
    "* While creating the regressor, set `random_state` to `RANDOM_STATE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "jdC9SkHkF1GQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6b8ee3fa1ad564798713a14fe8036ea",
     "grade": false,
     "grade_id": "cell-44c03b407ac47ea5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-8-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-8-Task-1\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = None\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ROWicw7MF1GS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5feb01b6f08b122058f72f2bcb27e0f3",
     "grade": true,
     "grade_id": "cell-e4cae8cf9d9a8b14",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-8-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "assert tree_reg is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KWdheVJDF1GW",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b8bdaf44a230569f78a4234743f5ec6",
     "grade": false,
     "grade_id": "cell-6f05e1a978f59a5f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now, let's evaluate the performance of the regression tree in the train and test set. Any regression metric like mean absolute error(MAE), residual sum of squares(RSS), mean squared error(MSE), etc. can be used for the evaluation. However, since you are familiar with MSE from linear regression, we will use MSE for the evaluation. To compute MSE, we will use [mean_squred_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) from scikit-learn.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZhAVsp9XF1GW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de0963a9651308acd22720d2102157a1",
     "grade": false,
     "grade_id": "cell-45870ba833cf0745",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred_train = tree_reg.predict(X_train)\n",
    "train_mse = mean_squared_error(y_pred_train, y_train)\n",
    "y_pred = tree_reg.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "XDuy9ZWeF1Ga",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "044b7e245ee47ab4c3a145c7a1eb1f79",
     "grade": false,
     "grade_id": "cell-6c97fee881c7007d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "ada9639c-b732-425f-a3a1-f654b56b43f5"
   },
   "outputs": [],
   "source": [
    "print(\"Train mse = {} and Test mse = {}\".format(round(train_mse, 2), round(test_mse, 2)))\n",
    "print(\"The depth of our tree is {}\".format(tree_clf.get_depth()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ytzndo3LF1Gf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e73e65f8b06b4a09da07ddbbb50eff96",
     "grade": false,
     "grade_id": "cell-886c1a64c03bbd4c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The regression tree we trained is very deep. Let us use early stopping to improve the performance of this tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "deletable": false,
    "editable": false,
    "id": "pt1AxF2ZF1Gg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea4ec28a28a43a343cdff48a8c568ba8",
     "grade": false,
     "grade_id": "cell-b8784c3e80f32196",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "14f44a14-d36c-4957-9317-51e2e3599141"
   },
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_socres = []\n",
    "for i in range(1, tree_clf.get_depth()+1):\n",
    "    model = DecisionTreeRegressor(random_state=RANDOM_STATE, max_depth=i).fit(X_train, y_train)\n",
    "    \n",
    "    # Computing mse in train set\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_scores.append(mean_squared_error(y_pred_train, y_train))# mse on train set\n",
    "  \n",
    "    # Computing mse on test set\n",
    "    y_pred = model.predict(X_test) # Making Predictions\n",
    "    test_socres.append(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "max_test_score = np.argmin(test_socres) + 1\n",
    "# Plot of depth vs accuracy\n",
    "depth = tree_clf.get_depth()\n",
    "plt.figure(figsize = (10,5))    \n",
    "plt.plot(np.arange(1, depth+1, 1), train_scores, marker = 'o', label = 'Train')\n",
    "plt.plot(np.arange(1, depth+1, 1), test_socres, marker = 'o', label = \"Test\")\n",
    "plt.plot([max_test_score,max_test_score], [0.02, 7.0], '--', color = 'black', alpha = 0.5)\n",
    "plt.xlabel(\"Depth/complexity\", fontsize = 17)\n",
    "plt.ylabel(\"Mean Squared Error(MSE)\", fontsize = 17)\n",
    "plt.title(\"Mean Squared Error for different depth of the regression tree\", fontsize = 17)\n",
    "plt.xticks(np.arange(1, depth+1, 1)) \n",
    "plt.yticks(np.arange(0.7, 1.05, 0.05))\n",
    "plt.legend(fontsize = 17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "M39ppdnXF1Gl",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1727a47218197d7183834b6c87cd2158",
     "grade": false,
     "grade_id": "cell-1589c4606c9552d3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Task:** \n",
    "\n",
    "\n",
    "Use the graph above to find out the least value for depth that yields the minimum MSE score on the test set and use it to set the `optimal_depth_reg` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "tVqXJmK0F1Gl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8fa3a19771159da712c7f1a4dc0d8f0",
     "grade": false,
     "grade_id": "cell-934493981085e551",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-8-Task-2"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-8-Task-2\n",
    "\n",
    "optimal_depth_reg = None\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "m2wkKs-yF1Gn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9a6380bafd2033c2b02fe4207b3e8a5",
     "grade": true,
     "grade_id": "cell-7bbff5e1079b5a5e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-8-Task-2"
    ]
   },
   "outputs": [],
   "source": [
    "assert optimal_depth_reg is not None, \"Please set optimal_depth to the least depth that yields minimum MSE on test set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9A8NvFrsF1Gp",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4364ffd415b5645bba8562c94594adc3",
     "grade": false,
     "grade_id": "cell-c27e86b11adbb4ce",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 9: Create depth limited Regression Tree\n",
    "\n",
    "\n",
    "**[POINTS: 1]** \n",
    "\n",
    "---\n",
    "\n",
    "**Task**\n",
    "\n",
    "* Using [`DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) model provided by `scikit-learn` create a regression tree and store it to the variable `model_reg`. \n",
    "    * Limit `max_depth` parameter to `optimal_depth_reg`.\n",
    "    * While creating the regressor, set `random_state` to `RANDOM_STATE`.\n",
    "    * Train the regressor using the `fit` method and data `X_train`, `y_train`.\n",
    "    * Compute the MSE score of `model_reg` on `X_test` and assign it to the variable `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "nfJCFyd6F1Gp",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffb8e7c2892bd4089bca21fa710d5797",
     "grade": false,
     "grade_id": "cell-bd32dee69b67c3bc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-9-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "### Ex-9-Task-1\n",
    "\n",
    "model_reg = None\n",
    "y_pred = None # Array to store predictions\n",
    "test = None # variable to hold f1-score of model on test set\n",
    "### BEGIN SOLUTION\n",
    "# your code here\n",
    "raise NotImplementedError\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2qsMqK5_F1Gr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6156a4759928768e728632fd35e2369d",
     "grade": true,
     "grade_id": "cell-364df8c486e2cbdf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-9-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "assert model_reg is not None, \"Please follow instructions and create a model with specified parameters\"\n",
    "assert test is not None, \"Please use variable test to store f1-score of the model on test set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "_H8LalR5F1Gs",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfbdff61c6e55f1f7fc3028275407aa1",
     "grade": false,
     "grade_id": "cell-5ca9964b1f7685c5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "a8046341-bc69-436c-bf2b-2c4c30e2669b"
   },
   "outputs": [],
   "source": [
    "print(\"The MSE on test set after pruning = {}\".format(round(test, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Gz2KdFkLF1Gu",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba3c694fd752984efb62fa10ce416a40",
     "grade": false,
     "grade_id": "cell-284a320f937dc021",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We see that by using early stopping, we have successfully improved the performance of our regression tree. The mean squared error has dropped from 5.86 to 4.62.  You may be able to further reduce the error by using cost-complexity pruning. However, as we have already used cost complexity pruning for classification, we won't play with it here. In your personal projects, you may play with both early stopping and pruning techniques to improve the performance and use the technique that gives better results."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_Instructor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
